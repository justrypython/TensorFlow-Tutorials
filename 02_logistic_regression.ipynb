{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "def init_weights(shape):\n",
    "    return tf.Variable(tf.random_normal(shape, stddev=0.01))\n",
    "\n",
    "def model(X, w):\n",
    "    return tf.matmul(X, w) # notice we use the same model as linear regression, this is because there is a baked in cost function which performs softmax and cross entropy\n",
    "\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n",
    "trX, trY, teX, teY = mnist.train.images, mnist.train.labels, mnist.test.images, mnist.test.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.placeholder(\"float\", [None, 784]) # create symbolic variables\n",
    "Y = tf.placeholder(\"float\", [None, 10])\n",
    "\n",
    "w = init_weights([784, 10]) # like in linear regression, we need a shared variable weight matrix for logistic regression\n",
    "\n",
    "py_x = model(X, w)\n",
    "\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=py_x, labels=Y)) # compute mean cross entropy (softmax is applied internally)\n",
    "train_op = tf.train.GradientDescentOptimizer(0.05).minimize(cost) # construct optimizer\n",
    "predict_op = tf.argmax(py_x, 1) # at predict time, evaluate the argmax of the logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.8842\n",
      "1 0.8976\n",
      "2 0.9038\n",
      "3 0.9074\n",
      "4 0.9099\n",
      "5 0.9106\n",
      "6 0.9117\n",
      "7 0.913\n",
      "8 0.9149\n",
      "9 0.9156\n",
      "10 0.9163\n",
      "11 0.9167\n",
      "12 0.9171\n",
      "13 0.9172\n",
      "14 0.9176\n",
      "15 0.9179\n",
      "16 0.9185\n",
      "17 0.919\n",
      "18 0.9197\n",
      "19 0.9197\n",
      "20 0.9196\n",
      "21 0.9199\n",
      "22 0.9204\n",
      "23 0.9205\n",
      "24 0.9204\n",
      "25 0.9207\n",
      "26 0.921\n",
      "27 0.9212\n",
      "28 0.9213\n",
      "29 0.9214\n",
      "30 0.9216\n",
      "31 0.9213\n",
      "32 0.9213\n",
      "33 0.9212\n",
      "34 0.9214\n",
      "35 0.9214\n",
      "36 0.9215\n",
      "37 0.9214\n",
      "38 0.9218\n",
      "39 0.9219\n",
      "40 0.9218\n",
      "41 0.9218\n",
      "42 0.922\n",
      "43 0.922\n",
      "44 0.9221\n",
      "45 0.922\n",
      "46 0.922\n",
      "47 0.9221\n",
      "48 0.9222\n",
      "49 0.922\n",
      "50 0.922\n",
      "51 0.922\n",
      "52 0.9222\n",
      "53 0.9222\n",
      "54 0.9224\n",
      "55 0.9223\n",
      "56 0.9226\n",
      "57 0.9225\n",
      "58 0.9228\n",
      "59 0.923\n",
      "60 0.9229\n",
      "61 0.9229\n",
      "62 0.9231\n",
      "63 0.9232\n",
      "64 0.9234\n",
      "65 0.9235\n",
      "66 0.9237\n",
      "67 0.9236\n",
      "68 0.9236\n",
      "69 0.9237\n",
      "70 0.9237\n",
      "71 0.9236\n",
      "72 0.9238\n",
      "73 0.9239\n",
      "74 0.924\n",
      "75 0.9238\n",
      "76 0.9237\n",
      "77 0.9237\n",
      "78 0.9236\n",
      "79 0.9239\n",
      "80 0.9238\n",
      "81 0.9238\n",
      "82 0.9237\n",
      "83 0.9238\n",
      "84 0.9238\n",
      "85 0.9237\n",
      "86 0.9237\n",
      "87 0.9237\n",
      "88 0.9236\n",
      "89 0.9236\n",
      "90 0.9235\n",
      "91 0.9235\n",
      "92 0.9235\n",
      "93 0.9236\n",
      "94 0.9235\n",
      "95 0.9236\n",
      "96 0.9236\n",
      "97 0.9237\n",
      "98 0.9237\n",
      "99 0.9237\n"
     ]
    }
   ],
   "source": [
    "# Launch the graph in a session\n",
    "with tf.Session() as sess:\n",
    "    # you need to initialize all variables\n",
    "    tf.global_variables_initializer().run()\n",
    "\n",
    "    for i in range(100):\n",
    "        for start, end in zip(range(0, len(trX), 128), range(128, len(trX)+1, 128)):\n",
    "            sess.run(train_op, feed_dict={X: trX[start:end], Y: trY[start:end]})\n",
    "        print(i, np.mean(np.argmax(teY, axis=1) ==\n",
    "                         sess.run(predict_op, feed_dict={X: teX})))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### below is my code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(55000, 784)\n",
      "(55000, 10)\n",
      "(10000, 784)\n",
      "(10000, 10)\n"
     ]
    }
   ],
   "source": [
    "print (trX.shape)\n",
    "print (trY.shape)\n",
    "print (teX.shape)\n",
    "print (teY.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'Variable:0' shape=(784, 10) dtype=float32_ref>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Print_2:0' shape=(784, 10) dtype=float32>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.Print(w, [w])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = w.value()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Variable/read:0' shape=(784, 10) dtype=float32>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = np.array(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = tf.placeholder('float', [None, 784])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function placeholder in module tensorflow.python.ops.array_ops:\n",
      "\n",
      "placeholder(dtype, shape=None, name=None)\n",
      "    Inserts a placeholder for a tensor that will be always fed.\n",
      "    \n",
      "    **Important**: This tensor will produce an error if evaluated. Its value must\n",
      "    be fed using the `feed_dict` optional argument to `Session.run()`,\n",
      "    `Tensor.eval()`, or `Operation.run()`.\n",
      "    \n",
      "    For example:\n",
      "    \n",
      "    ```python\n",
      "    x = tf.placeholder(tf.float32, shape=(1024, 1024))\n",
      "    y = tf.matmul(x, x)\n",
      "    \n",
      "    with tf.Session() as sess:\n",
      "      print(sess.run(y))  # ERROR: will fail because x was not fed.\n",
      "    \n",
      "      rand_array = np.random.rand(1024, 1024)\n",
      "      print(sess.run(y, feed_dict={x: rand_array}))  # Will succeed.\n",
      "    ```\n",
      "    \n",
      "    Args:\n",
      "      dtype: The type of elements in the tensor to be fed.\n",
      "      shape: The shape of the tensor to be fed (optional). If the shape is not\n",
      "        specified, you can feed a tensor of any shape.\n",
      "      name: A name for the operation (optional).\n",
      "    \n",
      "    Returns:\n",
      "      A `Tensor` that may be used as a handle for feeding a value, but not\n",
      "      evaluated directly.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(tf.placeholder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y = tf.placeholder('float', [None, 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function random_normal in module tensorflow.python.ops.random_ops:\n",
      "\n",
      "random_normal(shape, mean=0.0, stddev=1.0, dtype=tf.float32, seed=None, name=None)\n",
      "    Outputs random values from a normal distribution.\n",
      "    \n",
      "    Args:\n",
      "      shape: A 1-D integer Tensor or Python array. The shape of the output tensor.\n",
      "      mean: A 0-D Tensor or Python value of type `dtype`. The mean of the normal\n",
      "        distribution.\n",
      "      stddev: A 0-D Tensor or Python value of type `dtype`. The standard deviation\n",
      "        of the normal distribution.\n",
      "      dtype: The type of the output.\n",
      "      seed: A Python integer. Used to create a random seed for the distribution.\n",
      "        See\n",
      "        @{tf.set_random_seed}\n",
      "        for behavior.\n",
      "      name: A name for the operation (optional).\n",
      "    \n",
      "    Returns:\n",
      "      A tensor of the specified shape filled with random normal values.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(tf.random_normal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "w = init_weights([784, 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'Variable_1:0' shape=(784, 10) dtype=float32_ref>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "py_x = model(X, w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function reduce_mean in module tensorflow.python.ops.math_ops:\n",
      "\n",
      "reduce_mean(input_tensor, axis=None, keep_dims=False, name=None, reduction_indices=None)\n",
      "    Computes the mean of elements across dimensions of a tensor.\n",
      "    \n",
      "    Reduces `input_tensor` along the dimensions given in `axis`.\n",
      "    Unless `keep_dims` is true, the rank of the tensor is reduced by 1 for each\n",
      "    entry in `axis`. If `keep_dims` is true, the reduced dimensions\n",
      "    are retained with length 1.\n",
      "    \n",
      "    If `axis` has no entries, all dimensions are reduced, and a\n",
      "    tensor with a single element is returned.\n",
      "    \n",
      "    For example:\n",
      "    \n",
      "    ```python\n",
      "    # 'x' is [[1., 1.]\n",
      "    #         [2., 2.]]\n",
      "    tf.reduce_mean(x) ==> 1.5\n",
      "    tf.reduce_mean(x, 0) ==> [1.5, 1.5]\n",
      "    tf.reduce_mean(x, 1) ==> [1.,  2.]\n",
      "    ```\n",
      "    \n",
      "    Args:\n",
      "      input_tensor: The tensor to reduce. Should have numeric type.\n",
      "      axis: The dimensions to reduce. If `None` (the default),\n",
      "        reduces all dimensions.\n",
      "      keep_dims: If true, retains reduced dimensions with length 1.\n",
      "      name: A name for the operation (optional).\n",
      "      reduction_indices: The old (deprecated) name for axis.\n",
      "    \n",
      "    Returns:\n",
      "      The reduced tensor.\n",
      "    \n",
      "    @compatibility(numpy)\n",
      "    Equivalent to np.mean\n",
      "    @end_compatibility\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(tf.reduce_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function softmax_cross_entropy_with_logits in module tensorflow.python.ops.nn_ops:\n",
      "\n",
      "softmax_cross_entropy_with_logits(_sentinel=None, labels=None, logits=None, dim=-1, name=None)\n",
      "    Computes softmax cross entropy between `logits` and `labels`.\n",
      "    \n",
      "    Measures the probability error in discrete classification tasks in which the\n",
      "    classes are mutually exclusive (each entry is in exactly one class).  For\n",
      "    example, each CIFAR-10 image is labeled with one and only one label: an image\n",
      "    can be a dog or a truck, but not both.\n",
      "    \n",
      "    **NOTE:**  While the classes are mutually exclusive, their probabilities\n",
      "    need not be.  All that is required is that each row of `labels` is\n",
      "    a valid probability distribution.  If they are not, the computation of the\n",
      "    gradient will be incorrect.\n",
      "    \n",
      "    If using exclusive `labels` (wherein one and only\n",
      "    one class is true at a time), see `sparse_softmax_cross_entropy_with_logits`.\n",
      "    \n",
      "    **WARNING:** This op expects unscaled logits, since it performs a `softmax`\n",
      "    on `logits` internally for efficiency.  Do not call this op with the\n",
      "    output of `softmax`, as it will produce incorrect results.\n",
      "    \n",
      "    `logits` and `labels` must have the same shape `[batch_size, num_classes]`\n",
      "    and the same dtype (either `float16`, `float32`, or `float64`).\n",
      "    \n",
      "    **Note that to avoid confusion, it is required to pass only named arguments to\n",
      "    this function.**\n",
      "    \n",
      "    Args:\n",
      "      _sentinel: Used to prevent positional parameters. Internal, do not use.\n",
      "      labels: Each row `labels[i]` must be a valid probability distribution.\n",
      "      logits: Unscaled log probabilities.\n",
      "      dim: The class dimension. Defaulted to -1 which is the last dimension.\n",
      "      name: A name for the operation (optional).\n",
      "    \n",
      "    Returns:\n",
      "      A 1-D `Tensor` of length `batch_size` of the same type as `logits` with the\n",
      "      softmax cross entropy loss.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(tf.nn.softmax_cross_entropy_with_logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'MatMul_1:0' shape=(?, 10) dtype=float32>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "py_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Placeholder_3:0' shape=(?, 10) dtype=float32>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=py_x, labels=Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=py_x, labels=Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_op = tf.train.GradientDescentOptimizer(0.05).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predict_op = tf.argmax(py_x, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Launch the graph in a session\n",
    "with tf.Session() as sess:\n",
    "    # you need to initialize all variables\n",
    "    tf.global_variables_initializer().run()\n",
    "\n",
    "    for i in range(100):\n",
    "        for start, end in zip(range(0, len(trX), 128), range(128, len(trX)+1, 128)):\n",
    "            sess.run(train_op, feed_dict={X: trX[start:end], Y: trY[start:end]})\n",
    "        print(i, np.mean(np.argmax(teY, axis=1) ==\n",
    "                         sess.run(predict_op, feed_dict={X: teX})))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.8838\n",
      "1 0.8974\n",
      "2 0.9034\n",
      "3 0.9074\n",
      "4 0.9103\n",
      "5 0.911\n",
      "6 0.9123\n",
      "7 0.9128\n",
      "8 0.9148\n",
      "9 0.9156\n",
      "10 0.9159\n",
      "11 0.9162\n",
      "12 0.917\n",
      "13 0.9171\n",
      "14 0.918\n",
      "15 0.9181\n",
      "16 0.9186\n",
      "17 0.9188\n",
      "18 0.9193\n",
      "19 0.9195\n",
      "20 0.9197\n",
      "21 0.92\n",
      "22 0.9204\n",
      "23 0.9204\n",
      "24 0.9205\n",
      "25 0.9204\n",
      "26 0.9206\n",
      "27 0.9211\n",
      "28 0.9211\n",
      "29 0.9214\n",
      "30 0.9215\n",
      "31 0.9216\n",
      "32 0.9215\n",
      "33 0.9215\n",
      "34 0.9215\n",
      "35 0.9214\n",
      "36 0.9213\n",
      "37 0.9214\n",
      "38 0.9216\n",
      "39 0.9218\n",
      "40 0.9219\n",
      "41 0.9216\n",
      "42 0.9216\n",
      "43 0.922\n",
      "44 0.922\n",
      "45 0.922\n",
      "46 0.922\n",
      "47 0.922\n",
      "48 0.922\n",
      "49 0.922\n",
      "50 0.9219\n",
      "51 0.9219\n",
      "52 0.9219\n",
      "53 0.9219\n",
      "54 0.9222\n",
      "55 0.9224\n",
      "56 0.9224\n",
      "57 0.9223\n",
      "58 0.9225\n",
      "59 0.9225\n",
      "60 0.9227\n",
      "61 0.9229\n",
      "62 0.923\n",
      "63 0.9229\n",
      "64 0.923\n",
      "65 0.9231\n",
      "66 0.923\n",
      "67 0.923\n",
      "68 0.9232\n",
      "69 0.9232\n",
      "70 0.9232\n",
      "71 0.9233\n",
      "72 0.9234\n",
      "73 0.9234\n",
      "74 0.9235\n",
      "75 0.9235\n",
      "76 0.9235\n",
      "77 0.9235\n",
      "78 0.9234\n",
      "79 0.9235\n",
      "80 0.9235\n",
      "81 0.9235\n",
      "82 0.9235\n",
      "83 0.9236\n",
      "84 0.9236\n",
      "85 0.9235\n",
      "86 0.9235\n",
      "87 0.9235\n",
      "88 0.9236\n",
      "89 0.9235\n",
      "90 0.9235\n",
      "91 0.9236\n",
      "92 0.9235\n",
      "93 0.9236\n",
      "94 0.9236\n",
      "95 0.9236\n",
      "96 0.9235\n",
      "97 0.9234\n",
      "98 0.9235\n",
      "99 0.9235\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    tf.global_variables_initializer().run()\n",
    "    for i in range(100):\n",
    "        for start, end in zip(range(0, len(trX), 128), range(128, len(trX)+1, 128)):\n",
    "            sess.run(train_op, feed_dict={X: trX[start:end], Y: trY[start:end]})\n",
    "        print (i, np.mean(np.argmax(teY, axis=1) == sess.run(predict_op, feed_dict={X: teX})))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7, 2, 1, ..., 4, 5, 6], dtype=int64)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(teY, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 1 ..., 0 7 0]\n",
      "[0 0 1 ..., 0 7 0]\n",
      "[0 0 1 ..., 0 7 0]\n",
      "[0 0 1 ..., 0 7 0]\n",
      "[0 0 1 ..., 0 7 0]\n",
      "[0 0 1 ..., 0 7 0]\n",
      "[0 0 1 ..., 0 7 0]\n",
      "[0 0 1 ..., 0 7 0]\n",
      "[0 0 1 ..., 0 7 0]\n",
      "[0 0 1 ..., 0 7 0]\n",
      "[0 0 1 ..., 0 7 0]\n",
      "[0 0 1 ..., 0 7 0]\n",
      "[0 0 1 ..., 0 7 0]\n",
      "[0 0 1 ..., 0 7 0]\n",
      "[0 0 1 ..., 0 7 0]\n",
      "[0 0 1 ..., 0 7 0]\n",
      "[0 0 1 ..., 0 7 0]\n",
      "[0 0 1 ..., 0 7 0]\n",
      "[0 0 1 ..., 0 7 0]\n",
      "[0 0 1 ..., 0 7 0]\n",
      "[0 0 1 ..., 0 7 0]\n",
      "[0 0 1 ..., 0 7 0]\n",
      "[0 0 1 ..., 0 7 0]\n",
      "[0 0 1 ..., 0 7 0]\n",
      "[0 0 1 ..., 0 7 0]\n",
      "[0 0 1 ..., 0 7 0]\n",
      "[0 0 1 ..., 0 7 0]\n",
      "[0 0 1 ..., 0 7 0]\n",
      "[0 0 1 ..., 0 7 0]\n",
      "[0 0 1 ..., 0 7 0]\n",
      "[0 0 1 ..., 0 7 0]\n",
      "[0 0 1 ..., 0 7 0]\n",
      "[0 0 1 ..., 0 7 0]\n",
      "[0 0 1 ..., 0 7 0]\n",
      "[0 0 1 ..., 0 7 0]\n",
      "[0 0 1 ..., 0 7 0]\n",
      "[0 0 1 ..., 0 7 0]\n",
      "[0 0 1 ..., 0 7 0]\n",
      "[0 0 1 ..., 0 7 0]\n",
      "[0 0 1 ..., 0 7 0]\n",
      "[0 0 1 ..., 0 7 0]\n",
      "[0 0 1 ..., 0 7 0]\n",
      "[0 0 1 ..., 0 7 0]\n",
      "[0 0 1 ..., 0 7 0]\n",
      "[0 0 1 ..., 0 7 0]\n",
      "[0 0 1 ..., 0 7 0]\n",
      "[0 0 1 ..., 0 7 0]\n",
      "[0 0 1 ..., 0 7 0]\n",
      "[0 0 1 ..., 0 7 0]\n",
      "[0 0 1 ..., 0 7 0]\n",
      "[0 0 1 ..., 0 7 0]\n",
      "[0 0 1 ..., 0 7 0]\n",
      "[0 0 1 ..., 0 7 0]\n",
      "[0 0 1 ..., 0 7 0]\n",
      "[0 0 1 ..., 0 7 0]\n",
      "[0 0 1 ..., 0 7 0]\n",
      "[0 0 1 ..., 0 7 0]\n",
      "[0 0 1 ..., 0 7 0]\n",
      "[0 0 1 ..., 0 7 0]\n",
      "[0 0 1 ..., 0 7 0]\n",
      "[0 0 1 ..., 0 7 0]\n",
      "[0 0 1 ..., 0 7 0]\n",
      "[0 0 1 ..., 0 7 0]\n",
      "[0 0 1 ..., 0 7 0]\n",
      "[0 0 1 ..., 0 7 0]\n",
      "[0 0 1 ..., 0 7 0]\n",
      "[0 0 1 ..., 0 7 0]\n",
      "[0 0 1 ..., 0 7 0]\n",
      "[0 0 1 ..., 0 7 0]\n",
      "[0 0 1 ..., 0 7 0]\n",
      "[0 0 1 ..., 0 7 0]\n",
      "[0 0 1 ..., 0 7 0]\n",
      "[0 0 1 ..., 0 7 0]\n",
      "[0 0 1 ..., 0 7 0]\n",
      "[0 0 1 ..., 0 7 0]\n",
      "[0 0 1 ..., 0 7 0]\n",
      "[0 0 1 ..., 0 7 0]\n",
      "[0 0 1 ..., 0 7 0]\n",
      "[0 0 1 ..., 0 7 0]\n",
      "[0 0 1 ..., 0 7 0]\n",
      "[0 0 1 ..., 0 7 0]\n",
      "[0 0 1 ..., 0 7 0]\n",
      "[0 0 1 ..., 0 7 0]\n",
      "[0 0 1 ..., 0 7 0]\n",
      "[0 0 1 ..., 0 7 0]\n",
      "[0 0 1 ..., 0 7 0]\n",
      "[0 0 1 ..., 0 7 0]\n",
      "[0 0 1 ..., 0 7 0]\n",
      "[0 0 1 ..., 0 7 0]\n",
      "[0 0 1 ..., 0 7 0]\n",
      "[0 0 1 ..., 0 7 0]\n",
      "[0 0 1 ..., 0 7 0]\n",
      "[0 0 1 ..., 0 7 0]\n",
      "[0 0 1 ..., 0 7 0]\n",
      "[0 0 1 ..., 0 7 0]\n",
      "[0 0 1 ..., 0 7 0]\n",
      "[0 0 1 ..., 0 7 0]\n",
      "[0 0 1 ..., 0 7 0]\n",
      "[0 0 1 ..., 0 7 0]\n",
      "[0 0 1 ..., 0 7 0]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    tf.global_variables_initializer().run()\n",
    "    for i in range(100):\n",
    "        a = sess.run(predict_op, feed_dict={X: teX})\n",
    "        print (a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, ..., 0, 7, 0], dtype=int64)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000,)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
